services:
  # Jupyter-Notebook:
  jupyter:
    build:
      context: ./docker
      dockerfile: Dockerfile.jupyter
    container_name: jupyter
    environment:
      - JUPYTER_TOKEN=ndtien
    ports:
      - "8888:8888"
    volumes:
      - ./notebook:/home/jovyan/work
    networks:
      - project-network

  # Spark Master - Spark Worker
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - project-network
  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.5.0
    container_name: spark-worker
    hostname: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_LOCAL_IP=spark-worker
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    networks:
      - project-network

  # Hadoop: Phần này thì mình cũng không nắm rõ cách cấu hình cho lắm, 
  ## nên mình lấy cấu hình của hadoop.env từ một nguồn trên mạng về và áp dụng thôi.
  namenode:
    image: apache/hadoop:3.3.6
    container_name: namenode
    hostname: namenode
    command: [ "hdfs", "namenode" ]
    ports:
      - 9870:9870
    env_file:
      - ./hadoop/hadoop.env
    volumes:
      - E:/hadoop/data/namenode:/data/hdfs/namenode
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    networks:
      - project-network
  datanode:
    image: apache/hadoop:3.3.6
    container_name: datanode
    command: [ "hdfs", "datanode" ]
    env_file:
      - ./hadoop/hadoop.env
    volumes:
      - E:/Hadoop/data/datanode:/data/hdfs/datanode
    networks:
      - project-network
  resourcemanager:
    image: apache/hadoop:3.3.6
    container_name: resourcemanager
    hostname: resourcemanager
    command: [ "yarn", "resourcemanager" ]
    ports:
      - 8088:8088
    env_file:
      - ./hadoop/hadoop.env
    networks:
      - project-network
  nodemanager:
    image: apache/hadoop:3.3.6
    container_name: nodemanager
    command: [ "yarn", "nodemanager" ]
    env_file:
      - ./hadoop/hadoop.env
    networks:
      - project-network
  # Postgres: Dùng để lưu toàn bộ dữ liệu Gold
  postgres:
    image: postgres:16.4
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - E:/postgres/data:/var/lib/postgresql/data
      - ./initdb/postgres_init.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - project-network
  adminer:
    image: adminer
    container_name: postgres-express
    depends_on:
      - postgres
    restart: always
    ports:
      - "8082:8080"
    networks:
      - project-network

  # MongoDB: Dùng để lưu tên của các bộ phim
  mongodb:
    image: mongo:8.0.6
    restart: always
    container_name: mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    ports:
      - "27017:27017"
    volumes:
      - E:/mongo:/data/db
    networks:
      - project-network
  mongo-express:
    image: mongo-express
    container_name: mongo-express
    depends_on:
      - mongodb
    ports:
      - "8084:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_USERNAME}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_PASSWORD}
      ME_CONFIG_MONGODB_SERVER: mongodb
      ME_CONFIG_MONGODB_PORT: 27017
      ME_CONFIG_MONGODB_URL: mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@mongodb:27017/
      ME_CONFIG_BASICAUTH: false
    networks:
      - project-network
  # Airflow
  airflow:
    build:
      context: ./docker
      dockerfile: Dockerfile.airflow
    container_name: airflow
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dags/gettingdata:/opt/airflow/dags/gettingdata
      - ./dags/medalion:/opt/airflow/dags/medalion
      - ./dags/operations:/opt/airflow/dags/operations
    ports:
      - 8083:8080
    command: >
      bash -c '(airflow db init &&  airflow users create  --username ndtien --password ndtien --firstname Tien --lastname Nguyen --role Admin --email nguyendinhtien23012004@gmail.com); airflow webserver & airflow scheduler'
    networks:
      - project-network

networks:
  project-network:


